{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0355cc29-7fb5-4195-b6d4-bf6d6f88d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import moviepy.editor as mp\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8a7271-06dd-4602-a190-3dd05c147e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Paths and constants\n",
    "SAVED_MODEL_PATH = 'F:/SRC_Bhuvaneswari/typpo/Crimenet/W2V/Checkpoint/wav2vec2_epoch_10.pt'\n",
    "LABEL_MAP = {0: 'Normal', 1: 'Abuse', 2: 'Explosion', 3: 'Fighting', 4: 'Car Accident', 5: 'Shooting', 6: 'Riot'}\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Load Wav2Vec2 processor and model with saved weights\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\",\n",
    "    num_labels=len(LABEL_MAP)\n",
    ")\n",
    "model.load_state_dict(torch.load(SAVED_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# Function to extract audio from video\n",
    "def extract_audio_from_video(video_path, output_audio_path=\"temp_audio.wav\"):\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(output_audio_path, fps=SAMPLING_RATE)\n",
    "    return output_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6539b2-9d5d-44c1-b93f-c51255f499e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess audio and make predictions\n",
    "def predict_audio_class(audio_path):\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample to the model's expected sampling rate if necessary\n",
    "    if sample_rate != SAMPLING_RATE:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=SAMPLING_RATE)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Convert to mono if needed\n",
    "    waveform = waveform.mean(dim=0).numpy()\n",
    "    \n",
    "    # Process the audio\n",
    "    inputs = processor(waveform, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs.input_values)\n",
    "        logits = outputs.logits\n",
    "        predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return LABEL_MAP[predicted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0343f0f-1ee3-4036-bdc0-7385bb652d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function to extract audio from video and classify it\n",
    "def predict_audio_from_video(video_path):\n",
    "    temp_audio_path = extract_audio_from_video(video_path)\n",
    "    audio_class = predict_audio_class(temp_audio_path)\n",
    "    os.remove(temp_audio_path)  # Clean up temporary audio file\n",
    "    return audio_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d0f5e7-9cc1-4b3d-b975-a972983cc64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Predicted audio class: Fighting\n"
     ]
    }
   ],
   "source": [
    "video_file_path = \"E:/SRC-Bhuvaneswari/VAD_XDViolence/ViVi/Dataset/XD Violence/Test/Brick.Mansions.2014__#00-16-26_00-17-12_label_B1-0-0.mp4\"\n",
    "predicted_class = predict_audio_from_video(video_file_path)\n",
    "print(f\"Predicted audio class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59e293-9322-49ad-8ecd-2a231279afe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViVi",
   "language": "python",
   "name": "vivi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
